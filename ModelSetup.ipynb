{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "from sklearn.svm  import LinearSVC\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "load_dotenv()\n",
    "    \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "all_champions = np.array(['Aatrox', 'Ahri', 'Akali', 'Akshan', 'Alistar', 'Amumu', 'Anivia',\n",
    "                    'Annie', 'Aphelios', 'Ashe', 'AurelionSol', 'Azir', 'Bard',\n",
    "                    'Belveth', 'Blitzcrank', 'Brand', 'Braum', 'Briar', 'Caitlyn',\n",
    "                    'Camille', 'Cassiopeia', 'Chogath', 'Corki', 'Darius', 'Diana',\n",
    "                    'DrMundo', 'Draven', 'Ekko', 'Elise', 'Evelynn', 'Ezreal',\n",
    "                    'FiddleSticks', 'Fiora', 'Fizz', 'Galio', 'Gangplank', 'Garen',\n",
    "                    'Gnar', 'Gragas', 'Graves', 'Gwen', 'Hecarim', 'Heimerdinger',\n",
    "                    'Hwei', 'Illaoi', 'Irelia', 'Ivern', 'Janna', 'JarvanIV', 'Jax',\n",
    "                    'Jayce', 'Jhin', 'Jinx', 'KSante', 'Kaisa', 'Kalista', 'Karma',\n",
    "                    'Karthus', 'Kassadin', 'Katarina', 'Kayle', 'Kayn', 'Kennen',\n",
    "                    'Khazix', 'Kindred', 'Kled', 'KogMaw', 'Leblanc', 'LeeSin',\n",
    "                    'Leona', 'Lillia', 'Lissandra', 'Lucian', 'Lulu', 'Lux',\n",
    "                    'Malphite', 'Malzahar', 'Maokai', 'MasterYi', 'Milio',\n",
    "                    'MissFortune', 'MonkeyKing', 'Mordekaiser', 'Morgana', 'Naafiri',\n",
    "                    'Nami', 'Nasus', 'Nautilus', 'Neeko', 'Nidalee', 'Nilah',\n",
    "                    'Nocturne', 'Nunu', 'Olaf', 'Orianna', 'Ornn', 'Pantheon', 'Poppy',\n",
    "                    'Pyke', 'Qiyana', 'Quinn', 'Rakan', 'Rammus', 'RekSai', 'Rell',\n",
    "                    'Renata', 'Renekton', 'Rengar', 'Riven', 'Rumble', 'Ryze',\n",
    "                    'Samira', 'Sejuani', 'Senna', 'Seraphine', 'Sett', 'Shaco', 'Shen',\n",
    "                    'Shyvana', 'Singed', 'Sion', 'Sivir', 'Skarner', 'Smolder', 'Sona',\n",
    "                    'Soraka', 'Swain', 'Sylas', 'Syndra', 'TahmKench', 'Taliyah',\n",
    "                    'Talon', 'Taric', 'Teemo', 'Thresh', 'Tristana', 'Trundle',\n",
    "                    'Tryndamere', 'TwistedFate', 'Twitch', 'Udyr', 'Urgot', 'Varus',\n",
    "                    'Vayne', 'Veigar', 'Velkoz', 'Vex', 'Vi', 'Viego', 'Viktor',\n",
    "                    'Vladimir', 'Volibear', 'Warwick', 'Xayah', 'Xerath', 'XinZhao',\n",
    "                    'Yasuo', 'Yone', 'Yorick', 'Yuumi', 'Zac', 'Zed', 'Zeri', 'Ziggs',\n",
    "                    'Zilean', 'Zoe', 'Zyra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(region='NA1',game_mode='ARAM',patch='14.13'):\n",
    "    #gets data collected into a csv\n",
    "\n",
    "    #if using sqlalchemy\n",
    "    # engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "    conn = psycopg2.connect(\n",
    "        database = os.getenv('DB_NAME'),\n",
    "        host = os.getenv('DB_HOST'),\n",
    "        user = os.getenv('DB_USER'),\n",
    "        password = os.getenv('DB_PASSWORD'),\n",
    "        port = os.getenv('5432')\n",
    "    )\n",
    "\n",
    "    os.makedirs('MatchData', exist_ok=True)\n",
    "    csv_path = f'MatchData/{region}_{game_mode}_{patch}.csv'\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    patch = patch+'%'\n",
    "\n",
    "    query_sql = \"\"\"SELECT * \n",
    "    FROM match_data \n",
    "    WHERE region = %s \n",
    "    AND game_mode = %s \n",
    "    AND patch LIKE %s\"\"\"\n",
    "\n",
    "    query = cursor.mogrify(query_sql,(region, game_mode,patch))\n",
    "    query = query.decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(csv_path):\n",
    "            print(\"Csv found\")\n",
    "        else:\n",
    "            with open(csv_path,'w') as f:\n",
    "                cursor.copy_expert(\"COPY ({}) TO STDOUT WITH CSV HEADER\".format(query),f)\n",
    "            print(\"Copy to csv successful\")\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(region='NA1',game_mode='ARAM',elo='ANY',version='14.13'):\n",
    "    #features extraction, encoding and data verification\n",
    "    engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "    engine = create_engine(engine_name)\n",
    "    \n",
    "    version = version+'%'\n",
    "    elo = elo+'%'\n",
    "\n",
    "    if(elo == 'ANY%'):\n",
    "        query_sql = \"\"\"SELECT * \n",
    "        FROM match_data \n",
    "        WHERE region = %s \n",
    "        AND game_mode = %s \n",
    "        AND version LIKE %s\"\"\"\n",
    "        params = (region,game_mode,version)\n",
    "        \n",
    "    else:\n",
    "        query_sql = \"\"\"SELECT * \n",
    "        FROM match_data \n",
    "        WHERE region = %s \n",
    "        AND game_mode = %s \n",
    "        AND elo LIKE %s\n",
    "        AND version LIKE %s\"\"\"\n",
    "        params = (region, game_mode, elo, version)\n",
    "\n",
    "    df = pd.read_sql_query(query_sql,con=engine,params=params)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data(df = None):\n",
    "    df = df.dropna()\n",
    "    \n",
    "    blue_team = ['blue_one','blue_two','blue_three','blue_four', 'blue_five']\n",
    "    red_team = ['red_one', 'red_two', 'red_three', 'red_four', 'red_five']\n",
    "    \n",
    "    blue_team_encoded = np.zeros((len(df),len(all_champions)))\n",
    "    blue_team_columns = [f\"blue_{champ}\" for champ in all_champions]\n",
    "    red_team_encoded = np.zeros((len(df),len(all_champions)))\n",
    "    red_team_columns = [f\"red_{champ}\" for champ in all_champions]\n",
    "\n",
    "\n",
    "    for idx,row in df.iterrows():\n",
    "        for col in blue_team:\n",
    "            champ = row[col]\n",
    "            champ_index = np.where(all_champions == champ)[0]\n",
    "            blue_team_encoded[idx][champ_index] = 1\n",
    "\n",
    "        for col in red_team:\n",
    "            champ = row[col]\n",
    "            champ_index = np.where(all_champions == champ)[0]\n",
    "            red_team_encoded[idx][champ_index] = 1\n",
    "\n",
    "    blue_team_encoded = pd.DataFrame(blue_team_encoded,columns=blue_team_columns)\n",
    "    red_team_encoded = pd.DataFrame(red_team_encoded, columns=red_team_columns)\n",
    "\n",
    "    match_ids = df['match_id']\n",
    "\n",
    "    df = df.drop(columns=['id','region','match_id','game_mode','elo','version'])\n",
    "    df = df.drop(columns=blue_team)\n",
    "    df = df.drop(columns=red_team)\n",
    "    df = pd.concat([df,blue_team_encoded,red_team_encoded],axis=1)\n",
    "\n",
    "    return df, match_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftAnalysisNN(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(2,16,1)\n",
    "        self.conv2 = nn.Conv1d(16,32,1)\n",
    "        self.fc1 = nn.Linear(167 * 32 * 1,64)\n",
    "        self.fc2 = nn.Linear(64,2)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        logits = self.act(self.conv1(input))\n",
    "        logits = self.act(self.conv2(logits))\n",
    "        logits = logits.view(logits.size(0),-1)\n",
    "        logits = self.fc1(logits)\n",
    "        logits = self.fc2(logits)\n",
    "        \n",
    "        output = torch.softmax(logits,dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        split = int((df.shape[1]-1)/2)\n",
    "        blue_team = np.array(df.iloc[:,1:split+1])\n",
    "        red_team = np.array(df.iloc[:,split+1:df.shape[1]])\n",
    "        self.label = np.array(df.iloc[:,0])\n",
    "        self.input = np.concatenate((blue_team,red_team),axis=1)\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        split = int((self.data.shape[1]-1)/2)\n",
    "        blue_team = self.data.iloc[idx,1:split+1]\n",
    "        red_team = self.data.iloc[idx,split+1:self.data.shape[1]]\n",
    "\n",
    "        blue_team_tensor = torch.tensor(blue_team.values, dtype=torch.float32)\n",
    "        red_team_tensor = torch.tensor(red_team.values, dtype=torch.float32)\n",
    "\n",
    "        input = torch.stack((blue_team_tensor,red_team_tensor),dim=0).to(device)\n",
    "\n",
    "        label = self.data.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "        return {\n",
    "            'input': input,\n",
    "            'label' : label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,batch_size):\n",
    "    train_indices, test_indices = train_test_split(range(len(data)), test_size=0.2, random_state=42, shuffle=True)\n",
    "    train_dataset = Subset(data, train_indices)\n",
    "    test_dataset = Subset(data, test_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    train_inputs, test_inputs, train_labels, test_labels = train_test_split(data.input, data.label, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    return train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_loader, train_inputs, train_labels, num_epochs, paths):\n",
    "    SVC_model = LinearSVC(dual = 'auto')\n",
    "    GNB_model = GaussianNB()\n",
    "    channels = next(iter(train_loader))['input'].shape[1]\n",
    "    NN_model = DraftAnalysisNN(channels,channels).to(device)\n",
    "    \n",
    "    SVC_model.fit(train_inputs,train_labels)\n",
    "    GNB_model.fit(train_inputs,train_labels)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(NN_model.parameters(),lr=1e-4)\n",
    "\n",
    "    print(f'Starting training of {num_epochs} epochs')\n",
    "    NN_model.zero_grad()\n",
    "    NN_model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            input = batch['input']\n",
    "            label = batch['label']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = NN_model(input)\n",
    "            loss = criterion(output,label)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "\n",
    "    print(f'Saving models')\n",
    "    with open(paths['SVC'], 'wb') as file:\n",
    "        pickle.dump(SVC_model,file)\n",
    "    \n",
    "    with open(paths['GNB'],'wb') as file:\n",
    "        pickle.dump(GNB_model, file)\n",
    "    \n",
    "    torch.save(NN_model.state_dict(),paths['NN'])\n",
    "\n",
    "    return SVC_model, GNB_model, NN_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels):\n",
    "    SVC_predictions = SVC_model.predict(test_inputs)\n",
    "    GNB_predictions = GNB_model.predict(test_inputs)\n",
    "\n",
    "    \n",
    "    print('Testing Models')\n",
    "    NN_model.eval()\n",
    "    NN_predictions = []\n",
    "    labels = []\n",
    "    voting_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            input = batch['input']\n",
    "            label = batch['label'].cpu().numpy()\n",
    "\n",
    "            output = NN_model(input)\n",
    "            prediction = torch.argmax(output, dim=1)\n",
    "            NN_pred = prediction.cpu().numpy()\n",
    "\n",
    "            NN_predictions.extend(NN_pred)\n",
    "            labels.extend(label)\n",
    "\n",
    "            sklearn_input = input.flatten().cpu().numpy().reshape((input.shape[0], -1))\n",
    "            SVC_pred = SVC_model.predict(sklearn_input)\n",
    "            GNB_pred = GNB_model.predict(sklearn_input)\n",
    "\n",
    "            combined_preds = np.stack([NN_pred, SVC_pred, GNB_pred], axis=0)\n",
    "            voting_result = stats.mode(combined_preds)\n",
    "            voting_predictions.extend(voting_result[0])\n",
    "    \n",
    "    SVC_acc = accuracy_score(SVC_predictions, test_labels)\n",
    "    GNB_acc = accuracy_score(GNB_predictions, test_labels)\n",
    "    NN_acc = accuracy_score(NN_predictions,labels)\n",
    "    voting_acc = accuracy_score(voting_predictions, labels)\n",
    "    \n",
    "    print(f'SVC Accuracy: {SVC_acc:.2f}')\n",
    "    print(f'GNB Accuracy: {GNB_acc:.2f}')\n",
    "    print(f'NN Accuracy: {NN_acc:.2f}')\n",
    "    print(f'Voting Accuracy: {voting_acc:.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(SVC_model,GNB_model,NN_model, blue_team, red_team):\n",
    "    \n",
    "    if len(blue_team) != 5 or len(red_team) != 5:\n",
    "        raise ValueError(\"Both teams must have exactly 5 champions. \"\n",
    "                         f\"Current sizes - Blue team: {len(blue_team)}, Red team: {len(red_team)}\")\n",
    "    if len(blue_team) != len(set(blue_team)):\n",
    "        raise ValueError(\"Duplicate champions found in blue team\")\n",
    "    if len(red_team) != len(set(red_team)):\n",
    "        raise ValueError(\"Duplicate champions found in red team\")\n",
    "\n",
    "    blue_team_encoded = np.zeros(len(all_champions))\n",
    "    red_team_encoded = np.zeros(len(all_champions))\n",
    "\n",
    "    for champ in blue_team:\n",
    "        champ_index = np.where(all_champions == champ)[0]\n",
    "        if champ_index.size == 0:\n",
    "            raise ValueError(f\"Champion '{champ}' not found in list.\")\n",
    "        blue_team_encoded[champ_index] = 1\n",
    "\n",
    "    for champ in red_team:\n",
    "        champ_index = np.where(all_champions == champ)[0]\n",
    "        if champ_index.size == 0:\n",
    "            raise ValueError(f\"Champion '{champ}' not found in list.\")\n",
    "        red_team_encoded[champ_index] = 1\n",
    "\n",
    "    sklearn_input = np.concatenate((blue_team_encoded,red_team_encoded),axis=None).reshape(1,-1)\n",
    "    SVC_pred = SVC_model.predict(sklearn_input)\n",
    "    GNB_pred = GNB_model.predict(sklearn_input)\n",
    "    \n",
    "    nn_input = torch.vstack((torch.tensor(red_team_encoded),torch.tensor(blue_team_encoded))).float().unsqueeze(0).to(device)\n",
    "    output = NN_model(nn_input)\n",
    "    prediction = torch.argmax(output, dim=1)\n",
    "    NN_pred = prediction.cpu().numpy()\n",
    "\n",
    "    combined_preds = np.stack([NN_pred, SVC_pred, GNB_pred], axis=0)\n",
    "    voting_result = stats.mode(combined_preds)[0]\n",
    "\n",
    "    if voting_result == 0:\n",
    "        winner = 'Blue Team'\n",
    "    else:\n",
    "        winner = 'Red Team'\n",
    "    \n",
    "    winner = 'Blue Team' if voting_result == 0 else 'Red Team'\n",
    "    \n",
    "    print(f'Predicted winner is {winner}')\n",
    "    print(f'SVC model predicted {\"Blue Team\" if SVC_pred[0] == 0 else \"Red Team\"}')\n",
    "    print(f'GNB model predicted {\"Blue Team\" if GNB_pred[0] == 0 else \"Red Team\"}')\n",
    "    print(f'NN model predicted {\"Blue Team\" if NN_pred[0] == 0 else \"Red Team\"} with a {output[0][0]*100 if NN_pred[0] == 0 else output[0][1]*100:.2f}% chance')\n",
    "\n",
    "    return sklearn_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_game(encoded_data, threshold, inputs, labels, match_ids):\n",
    "    matching_elements = (inputs == 1) & (encoded_data == 1)\n",
    "    match_counts = np.sum(matching_elements, axis=1)\n",
    "    matching_ids = match_ids[match_counts >= threshold]\n",
    "    matching_labels = labels[match_counts >= threshold]\n",
    "    \n",
    "\n",
    "    for idx, id in enumerate(matching_ids):\n",
    "        region, id_num = id.split('_')\n",
    "        if region == 'NA1':\n",
    "            region = 'NA'\n",
    "        region = region.lower()\n",
    "        winner = 'Blue Team' if matching_labels[idx] else 'Red Team'\n",
    "        print(f'https://www.leagueofgraphs.com/match/{region}/{id_num}, {winner} won')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5072 games with given settings\n",
      "Models exist, loading models\n",
      "Predicted winner is Blue Team\n",
      "SVC model predicted Blue Team\n",
      "GNB model predicted Blue Team\n",
      "NN model predicted Red Team with a 91.27% chance\n",
      "https://www.leagueofgraphs.com/match/na/5031350501, Red Team won\n",
      "https://www.leagueofgraphs.com/match/na/5033024012, Blue Team won\n",
      "https://www.leagueofgraphs.com/match/na/5034209383, Red Team won\n",
      "https://www.leagueofgraphs.com/match/na/5032007742, Blue Team won\n",
      "https://www.leagueofgraphs.com/match/na/5033227784, Red Team won\n",
      "https://www.leagueofgraphs.com/match/na/5035401246, Blue Team won\n",
      "https://www.leagueofgraphs.com/match/na/5035492196, Red Team won\n"
     ]
    }
   ],
   "source": [
    "def main(region, game_mode, elo, version, batch_size, num_epochs, override, blue_team, red_team, threshold):\n",
    "    #train_test,models if it does not exist. Otherwise load models and predict whether blue or red team will win based on the given champions\n",
    "    \n",
    "    prefix = f'Models/{region}_{game_mode}_{elo}_{version}_'\n",
    "    paths = {\n",
    "        'SVC' : prefix+'svc_model.pkl',\n",
    "        'GNB' : prefix+'gnb_model.pkl',\n",
    "        'NN' : prefix+'nn_model.pth'\n",
    "    }\n",
    "\n",
    "    df = get_data(region,game_mode,elo,version)\n",
    "    df, match_ids = verify_data(df)\n",
    "    data = MatchDataset(df) \n",
    "    print(f'Found {len(match_ids)} games with given settings')\n",
    "\n",
    "    if(override or not all(os.path.exists(path) for path in paths.values())):\n",
    "        print('Override is true or model(s) missing, training/testing models')\n",
    "        train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels = split_data(data,batch_size)\n",
    "        SVC_model, GNB_model, NN_model = train_models(train_loader,train_inputs, train_labels, num_epochs, paths)\n",
    "        test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels)\n",
    "    else:\n",
    "        print('Models exist, loading models')\n",
    "        with open(paths['SVC'],'rb') as file:\n",
    "            SVC_model = pickle.load(file)\n",
    "    \n",
    "        with open(paths['GNB'],'rb') as file:\n",
    "            GNB_model = pickle.load(file)\n",
    "\n",
    "        NN_model = DraftAnalysisNN(2,2).to(device)\n",
    "        NN_model.load_state_dict(torch.load(paths['NN']))\n",
    "\n",
    "    \n",
    "    encoded_data = predict(SVC_model,GNB_model,NN_model, blue_team, red_team)\n",
    "    get_similar_game(encoded_data[0],threshold,data.input,data.label, match_ids)\n",
    "    #get old games based on threshold value, if threshold = 5, get all games where 5 champions match up to our 5 champions (on same team)\n",
    "    \n",
    "blue_team = ['Karthus','DrMundo','Janna','Thresh','Samira']\n",
    "red_team = ['Fiora','Karma','Chogath','Zoe','Tryndamere']\n",
    "main('NA1','ARAM','ANY','14.13', batch_size = 1, num_epochs = 5, override= False, blue_team=blue_team, red_team=red_team, threshold = 3 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
