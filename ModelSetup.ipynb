{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "from sklearn.svm  import LinearSVC\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "load_dotenv()\n",
    "    \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "all_champions = np.array(['Aatrox', 'Ahri', 'Akali', 'Akshan', 'Alistar', 'Amumu', 'Anivia',\n",
    "                    'Annie', 'Aphelios', 'Ashe', 'AurelionSol', 'Azir', 'Bard',\n",
    "                    'Belveth', 'Blitzcrank', 'Brand', 'Braum', 'Briar', 'Caitlyn',\n",
    "                    'Camille', 'Cassiopeia', 'Chogath', 'Corki', 'Darius', 'Diana',\n",
    "                    'DrMundo', 'Draven', 'Ekko', 'Elise', 'Evelynn', 'Ezreal',\n",
    "                    'FiddleSticks', 'Fiora', 'Fizz', 'Galio', 'Gangplank', 'Garen',\n",
    "                    'Gnar', 'Gragas', 'Graves', 'Gwen', 'Hecarim', 'Heimerdinger',\n",
    "                    'Hwei', 'Illaoi', 'Irelia', 'Ivern', 'Janna', 'JarvanIV', 'Jax',\n",
    "                    'Jayce', 'Jhin', 'Jinx', 'KSante', 'Kaisa', 'Kalista', 'Karma',\n",
    "                    'Karthus', 'Kassadin', 'Katarina', 'Kayle', 'Kayn', 'Kennen',\n",
    "                    'Khazix', 'Kindred', 'Kled', 'KogMaw', 'Leblanc', 'LeeSin',\n",
    "                    'Leona', 'Lillia', 'Lissandra', 'Lucian', 'Lulu', 'Lux',\n",
    "                    'Malphite', 'Malzahar', 'Maokai', 'MasterYi', 'Milio',\n",
    "                    'MissFortune', 'MonkeyKing', 'Mordekaiser', 'Morgana', 'Naafiri',\n",
    "                    'Nami', 'Nasus', 'Nautilus', 'Neeko', 'Nidalee', 'Nilah',\n",
    "                    'Nocturne', 'Nunu', 'Olaf', 'Orianna', 'Ornn', 'Pantheon', 'Poppy',\n",
    "                    'Pyke', 'Qiyana', 'Quinn', 'Rakan', 'Rammus', 'RekSai', 'Rell',\n",
    "                    'Renata', 'Renekton', 'Rengar', 'Riven', 'Rumble', 'Ryze',\n",
    "                    'Samira', 'Sejuani', 'Senna', 'Seraphine', 'Sett', 'Shaco', 'Shen',\n",
    "                    'Shyvana', 'Singed', 'Sion', 'Sivir', 'Skarner', 'Smolder', 'Sona',\n",
    "                    'Soraka', 'Swain', 'Sylas', 'Syndra', 'TahmKench', 'Taliyah',\n",
    "                    'Talon', 'Taric', 'Teemo', 'Thresh', 'Tristana', 'Trundle',\n",
    "                    'Tryndamere', 'TwistedFate', 'Twitch', 'Udyr', 'Urgot', 'Varus',\n",
    "                    'Vayne', 'Veigar', 'Velkoz', 'Vex', 'Vi', 'Viego', 'Viktor',\n",
    "                    'Vladimir', 'Volibear', 'Warwick', 'Xayah', 'Xerath', 'XinZhao',\n",
    "                    'Yasuo', 'Yone', 'Yorick', 'Yuumi', 'Zac', 'Zed', 'Zeri', 'Ziggs',\n",
    "                    'Zilean', 'Zoe', 'Zyra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(region='NA1',game_mode='ARAM',patch='14.13'):\n",
    "    #gets data collected into a csv\n",
    "\n",
    "    #if using sqlalchemy\n",
    "    # engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "    conn = psycopg2.connect(\n",
    "        database = os.getenv('DB_NAME'),\n",
    "        host = os.getenv('DB_HOST'),\n",
    "        user = os.getenv('DB_USER'),\n",
    "        password = os.getenv('DB_PASSWORD'),\n",
    "        port = os.getenv('5432')\n",
    "    )\n",
    "\n",
    "    os.makedirs('MatchData', exist_ok=True)\n",
    "    csv_path = f'MatchData/{region}_{game_mode}_{patch}.csv'\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    patch = patch+'%'\n",
    "\n",
    "    query_sql = \"\"\"SELECT * \n",
    "    FROM match_data \n",
    "    WHERE region = %s \n",
    "    AND game_mode = %s \n",
    "    AND patch LIKE %s\"\"\"\n",
    "\n",
    "    query = cursor.mogrify(query_sql,(region, game_mode,patch))\n",
    "    query = query.decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(csv_path):\n",
    "            print(\"Csv found\")\n",
    "        else:\n",
    "            with open(csv_path,'w') as f:\n",
    "                cursor.copy_expert(\"COPY ({}) TO STDOUT WITH CSV HEADER\".format(query),f)\n",
    "            print(\"Copy to csv successful\")\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(region='NA1',game_mode='ARAM',elo='ANY',version='14.13'):\n",
    "    #features extraction, encoding and data verification\n",
    "    engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "    engine = create_engine(engine_name)\n",
    "    \n",
    "    version = version+'%'\n",
    "    elo = elo+'%'\n",
    "\n",
    "    if(elo == 'ANY%'):\n",
    "        query_sql = \"\"\"SELECT * \n",
    "        FROM match_data \n",
    "        WHERE region = %s \n",
    "        AND game_mode = %s \n",
    "        AND version LIKE %s\"\"\"\n",
    "        params = (region,game_mode,version)\n",
    "        \n",
    "    else:\n",
    "        query_sql = \"\"\"SELECT * \n",
    "        FROM match_data \n",
    "        WHERE region = %s \n",
    "        AND game_mode = %s \n",
    "        AND elo LIKE %s\n",
    "        AND version LIKE %s\"\"\"\n",
    "        params = (region, game_mode, elo, version)\n",
    "\n",
    "    df = pd.read_sql_query(query_sql,con=engine,params=params)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data(df = None):\n",
    "    df = df.dropna()\n",
    "    \n",
    "    blue_team = ['blue_one','blue_two','blue_three','blue_four', 'blue_five']\n",
    "    red_team = ['red_one', 'red_two', 'red_three', 'red_four', 'red_five']\n",
    "    \n",
    "    blue_team_encoded = np.zeros((len(df),len(all_champions)))\n",
    "    blue_team_columns = [f\"blue_{champ}\" for champ in all_champions]\n",
    "    red_team_encoded = np.zeros((len(df),len(all_champions)))\n",
    "    red_team_columns = [f\"red_{champ}\" for champ in all_champions]\n",
    "\n",
    "\n",
    "    for idx,row in df.iterrows():\n",
    "        for col in blue_team:\n",
    "            champ = row[col]\n",
    "            champ_index = np.where(all_champions == champ)[0]\n",
    "            blue_team_encoded[idx][champ_index] = 1\n",
    "\n",
    "        for col in red_team:\n",
    "            champ = row[col]\n",
    "            champ_index = np.where(all_champions == champ)[0]\n",
    "            red_team_encoded[idx][champ_index] = 1\n",
    "\n",
    "    blue_team_encoded = pd.DataFrame(blue_team_encoded,columns=blue_team_columns)\n",
    "    red_team_encoded = pd.DataFrame(red_team_encoded, columns=red_team_columns)\n",
    "\n",
    "    df = df.drop(columns=['id','match_id','region','game_mode','elo','version'])\n",
    "    df = df.drop(columns=blue_team)\n",
    "    df = df.drop(columns=red_team)\n",
    "    df = pd.concat([df,blue_team_encoded,red_team_encoded],axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftAnalysisNN(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(2,16,1)\n",
    "        self.conv2 = nn.Conv1d(16,32,1)\n",
    "        self.fc1 = nn.Linear(167 * 32 * 1,64)\n",
    "        self.fc2 = nn.Linear(64,2)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        logits = self.act(self.conv1(input))\n",
    "        logits = self.act(self.conv2(logits))\n",
    "        logits = logits.view(logits.size(0),-1)\n",
    "        logits = self.fc1(logits)\n",
    "        logits = self.fc2(logits)\n",
    "        \n",
    "        output = torch.softmax(logits,dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        split = int((df.shape[1]-1)/2)\n",
    "        blue_team = np.array(df.iloc[:,1:split+1])\n",
    "        red_team = np.array(df.iloc[:,split+1:df.shape[1]])\n",
    "        self.label = df.iloc[:,0]\n",
    "        self.input = np.concatenate((blue_team,red_team),axis=1)\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        split = int((self.data.shape[1]-1)/2)\n",
    "        blue_team = self.data.iloc[idx,1:split+1]\n",
    "        red_team = self.data.iloc[idx,split+1:self.data.shape[1]]\n",
    "\n",
    "        blue_team_tensor = torch.tensor(blue_team.values, dtype=torch.float32)\n",
    "        red_team_tensor = torch.tensor(red_team.values, dtype=torch.float32)\n",
    "\n",
    "        input = torch.stack((blue_team_tensor,red_team_tensor),dim=0).to(device)\n",
    "\n",
    "        label = self.data.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "        return {\n",
    "            'input': input,\n",
    "            'label' : label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,batch_size):\n",
    "    train_indices, test_indices = train_test_split(range(len(data)), test_size=0.2, random_state=42, shuffle=True)\n",
    "    train_dataset = Subset(data, train_indices)\n",
    "    test_dataset = Subset(data, test_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    train_inputs, test_inputs, train_labels, test_labels = train_test_split(data.input, data.label, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    return train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_loader, train_inputs, train_labels, num_epochs, paths):\n",
    "    SVC_model = LinearSVC(dual = 'auto')\n",
    "    GNB_model = GaussianNB()\n",
    "    channels = next(iter(train_loader))['input'].shape[1]\n",
    "    NN_model = DraftAnalysisNN(channels,channels).to(device)\n",
    "    \n",
    "    SVC_model.fit(train_inputs,train_labels)\n",
    "    GNB_model.fit(train_inputs,train_labels)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(NN_model.parameters(),lr=1e-4)\n",
    "\n",
    "    print(f'Starting training of {num_epochs} epochs')\n",
    "    NN_model.zero_grad()\n",
    "    NN_model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            input = batch['input']\n",
    "            label = batch['label']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = NN_model(input)\n",
    "            loss = criterion(output,label)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "\n",
    "    print(f'Saving models')\n",
    "    with open(paths['SVC'], 'wb') as file:\n",
    "        pickle.dump(SVC_model,file)\n",
    "    \n",
    "    with open(paths['GNB'],'wb') as file:\n",
    "        pickle.dump(GNB_model, file)\n",
    "    \n",
    "    torch.save(NN_model.state_dict(),paths['NN'])\n",
    "\n",
    "    return SVC_model, GNB_model, NN_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels):\n",
    "    SVC_predictions = SVC_model.predict(test_inputs)\n",
    "    GNB_predictions = GNB_model.predict(test_inputs)\n",
    "\n",
    "    \n",
    "    print('Testing Models')\n",
    "    NN_model.eval()\n",
    "    NN_predictions = []\n",
    "    labels = []\n",
    "    voting_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            input = batch['input']\n",
    "            label = batch['label'].cpu().numpy()\n",
    "\n",
    "            output = NN_model(input)\n",
    "            prediction = torch.argmax(output, dim=1)\n",
    "            NN_pred = prediction.cpu().numpy()\n",
    "\n",
    "            NN_predictions.extend(NN_pred)\n",
    "            labels.extend(label)\n",
    "\n",
    "            sklearn_input = input.flatten().cpu().numpy().reshape((input.shape[0], -1))\n",
    "            SVC_pred = SVC_model.predict(sklearn_input)\n",
    "            GNB_pred = GNB_model.predict(sklearn_input)\n",
    "\n",
    "            combined_preds = np.stack([NN_pred, SVC_pred, GNB_pred], axis=0)\n",
    "            voting_result = stats.mode(combined_preds)\n",
    "            voting_predictions.extend(voting_result[0])\n",
    "    \n",
    "    SVC_acc = accuracy_score(SVC_predictions, test_labels)\n",
    "    GNB_acc = accuracy_score(GNB_predictions, test_labels)\n",
    "    NN_acc = accuracy_score(NN_predictions,labels)\n",
    "    voting_acc = accuracy_score(voting_predictions, labels)\n",
    "    \n",
    "    print(f'SVC Accuracy: {SVC_acc:.2f}')\n",
    "    print(f'GNB Accuracy: {GNB_acc:.2f}')\n",
    "    print(f'NN Accuracy: {NN_acc:.2f}')\n",
    "    print(f'Voting Accuracy: {voting_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_models(region,game_mode,elo,version,batch_size,num_epochs, paths):\n",
    "    #get_csv(region=region,game_mode=game_mode,patch=patch)\n",
    "    #data extraction\n",
    "    df = get_data(region,game_mode,elo,version)\n",
    "    #data encoding + validation\n",
    "    df = verify_data(df)\n",
    "    data = MatchDataset(df) \n",
    "    #build model + training\n",
    "    train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels = split_data(data,batch_size)\n",
    "    SVC_model, GNB_model, NN_model = train_models(train_loader,train_inputs, train_labels, num_epochs, paths)\n",
    "    test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels)\n",
    "\n",
    "    return SVC_model, GNB_model, NN_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(SVC_model,GNB_model,NN_model, blue_team, red_team):\n",
    "    blue_team_encoded = np.zeros(len(all_champions))\n",
    "    red_team_encoded = np.zeros(len(all_champions))\n",
    "\n",
    "    for champ in blue_team:\n",
    "        champ_index = np.where(all_champions == champ)[0]\n",
    "        blue_team_encoded[champ_index] = 1\n",
    "\n",
    "    for champ in red_team:\n",
    "        champ_index = np.where(all_champions == champ)[0]\n",
    "        red_team_encoded[champ_index] = 1\n",
    "\n",
    "    sklearn_input = np.concatenate((blue_team_encoded,red_team_encoded),axis=None).reshape(1,-1)\n",
    "    SVC_pred = SVC_model.predict(sklearn_input)\n",
    "    GNB_pred = GNB_model.predict(sklearn_input)\n",
    "    \n",
    "    nn_input = torch.vstack((torch.tensor(red_team_encoded),torch.tensor(blue_team_encoded))).float().unsqueeze(0)\n",
    "    output = NN_model(nn_input)\n",
    "    prediction = torch.argmax(output, dim=1)\n",
    "    NN_pred = prediction.cpu().numpy()\n",
    "\n",
    "    combined_preds = np.stack([NN_pred, SVC_pred, GNB_pred], axis=0)\n",
    "    voting_result = stats.mode(combined_preds)[0]\n",
    "\n",
    "    if voting_result == 0:\n",
    "        winner = 'Blue Team'\n",
    "    else:\n",
    "        winner = 'Red Team'\n",
    "    \n",
    "    winner = 'Blue Team' if voting_result == 0 else 'Red Team'\n",
    "    \n",
    "    print(f'Predicted winner is {winner}')\n",
    "    print(f'SVC model predicted {\"Blue Team\" if SVC_pred[0] == 0 else \"Red Team\"}')\n",
    "    print(f'GNB model predicted {\"Blue Team\" if GNB_pred[0] == 0 else \"Red Team\"}')\n",
    "    print(f'NN model predicted {\"Blue Team\" if NN_pred[0] == 0 else \"Red Team\"} with a {output[0][0]:.4f}% chance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models exist, loading models\n",
      "Predicted winner is Blue Team\n",
      "SVC model predicted Blue Team\n",
      "GNB model predicted Blue Team\n",
      "NN model predicted Blue Team with a 0.5369874835014343% chance\n",
      "tensor([[0.5370, 0.4630]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def main(region, game_mode, elo, version, batch_size, num_epochs, override, blue_team, red_team):\n",
    "    #train_test,models if it does not exist. Otherwise load models and predict whether blue or red team will win based on the given champions\n",
    "    prefix = f'Models/{region}_{game_mode}_{elo}_{version}_'\n",
    "    paths = {\n",
    "        'SVC' : prefix+'svc_model.pkl',\n",
    "        'GNB' : prefix+'gnb_model.pkl',\n",
    "        'NN' : prefix+'nn_model.pth'\n",
    "    }\n",
    "    if(override or not all(os.path.exists(path) for path in paths.values())):\n",
    "        print('Model(s) missing, training/testing models')\n",
    "        SVC_model, GNB_model, NN_model = train_test_models(region,game_mode,elo,version, batch_size, num_epochs, paths)\n",
    "    else:\n",
    "        print('Models exist, loading models')\n",
    "        with open(paths['SVC'],'rb') as file:\n",
    "            SVC_model = pickle.load(file)\n",
    "    \n",
    "        with open(paths['GNB'],'rb') as file:\n",
    "            GNB_model = pickle.load(file)\n",
    "\n",
    "        NN_model = DraftAnalysisNN(2,2)\n",
    "        NN_model.load_state_dict(torch.load(paths['NN']))\n",
    "\n",
    "    winner = predict(SVC_model,GNB_model,NN_model, blue_team, red_team)\n",
    "    return winner\n",
    "blue_team = ['Renekton','Fizz','Zac','Ryze','Jayce']\n",
    "red_team = ['Xerath','Maokai','Ahri','LeeSin','Aphelios']\n",
    "main('NA1','ARAM','ANY','14.13', batch_size = 1, num_epochs = 1, override=False, blue_team=blue_team, red_team=red_team)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
