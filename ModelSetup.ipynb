{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "from sklearn.svm  import LinearSVC\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "#loads global variables\n",
    "\n",
    "load_dotenv()\n",
    "    \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "all_champions = np.array(['Aatrox', 'Ahri', 'Akali', 'Akshan', 'Alistar', 'Amumu', 'Anivia',\n",
    "                    'Annie', 'Aphelios', 'Ashe', 'AurelionSol', 'Aurora', 'Azir', 'Bard',\n",
    "                    'Belveth', 'Blitzcrank', 'Brand', 'Braum', 'Briar', 'Caitlyn',\n",
    "                    'Camille', 'Cassiopeia', 'Chogath', 'Corki', 'Darius', 'Diana',\n",
    "                    'DrMundo', 'Draven', 'Ekko', 'Elise', 'Evelynn', 'Ezreal',\n",
    "                    'FiddleSticks', 'Fiora', 'Fizz', 'Galio', 'Gangplank', 'Garen',\n",
    "                    'Gnar', 'Gragas', 'Graves', 'Gwen', 'Hecarim', 'Heimerdinger',\n",
    "                    'Hwei', 'Illaoi', 'Irelia', 'Ivern', 'Janna', 'JarvanIV', 'Jax',\n",
    "                    'Jayce', 'Jhin', 'Jinx', 'KSante', 'Kaisa', 'Kalista', 'Karma',\n",
    "                    'Karthus', 'Kassadin', 'Katarina', 'Kayle', 'Kayn', 'Kennen',\n",
    "                    'Khazix', 'Kindred', 'Kled', 'KogMaw', 'Leblanc', 'LeeSin',\n",
    "                    'Leona', 'Lillia', 'Lissandra', 'Lucian', 'Lulu', 'Lux',\n",
    "                    'Malphite', 'Malzahar', 'Maokai', 'MasterYi', 'Milio',\n",
    "                    'MissFortune', 'MonkeyKing', 'Mordekaiser', 'Morgana', 'Naafiri',\n",
    "                    'Nami', 'Nasus', 'Nautilus', 'Neeko', 'Nidalee', 'Nilah',\n",
    "                    'Nocturne', 'Nunu', 'Olaf', 'Orianna', 'Ornn', 'Pantheon', 'Poppy',\n",
    "                    'Pyke', 'Qiyana', 'Quinn', 'Rakan', 'Rammus', 'RekSai', 'Rell',\n",
    "                    'Renata', 'Renekton', 'Rengar', 'Riven', 'Rumble', 'Ryze',\n",
    "                    'Samira', 'Sejuani', 'Senna', 'Seraphine', 'Sett', 'Shaco', 'Shen',\n",
    "                    'Shyvana', 'Singed', 'Sion', 'Sivir', 'Skarner', 'Smolder', 'Sona',\n",
    "                    'Soraka', 'Swain', 'Sylas', 'Syndra', 'TahmKench', 'Taliyah',\n",
    "                    'Talon', 'Taric', 'Teemo', 'Thresh', 'Tristana', 'Trundle',\n",
    "                    'Tryndamere', 'TwistedFate', 'Twitch', 'Udyr', 'Urgot', 'Varus',\n",
    "                    'Vayne', 'Veigar', 'Velkoz', 'Vex', 'Vi', 'Viego', 'Viktor',\n",
    "                    'Vladimir', 'Volibear', 'Warwick', 'Xayah', 'Xerath', 'XinZhao',\n",
    "                    'Yasuo', 'Yone', 'Yorick', 'Yuumi', 'Zac', 'Zed', 'Zeri', 'Ziggs',\n",
    "                    'Zilean', 'Zoe', 'Zyra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(region, game_mode, elo, version):\n",
    "    # Initiates SQL engine and uses it to get data given user settings and returns it as a dataframe\n",
    "    engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "    engine = create_engine(engine_name)\n",
    "    \n",
    "    # Initialize query parts\n",
    "    query_sql = \"SELECT * FROM match_data\"\n",
    "    params = []\n",
    "    \n",
    "    # Add conditions dynamically based on inputs\n",
    "    if region != 'ANY':\n",
    "        if params:\n",
    "            query_sql += \" AND\"\n",
    "        else:\n",
    "            query_sql += \" WHERE\"\n",
    "        query_sql += \" region = %s\"\n",
    "        params.append(region)\n",
    "    \n",
    "    if game_mode != 'ANY':\n",
    "        if params:\n",
    "            query_sql += \" AND\"\n",
    "        else:\n",
    "            query_sql += \" WHERE\"\n",
    "        query_sql += \" game_mode = %s\"\n",
    "        params.append(game_mode)\n",
    "    \n",
    "    if elo != 'ANY':\n",
    "        if params:\n",
    "            query_sql += \" AND\"\n",
    "        else:\n",
    "            query_sql += \" WHERE\"\n",
    "        query_sql += \" elo LIKE %s\"\n",
    "        params.append(elo + '%')\n",
    "    \n",
    "    if version != 'ANY':\n",
    "        if params:\n",
    "            query_sql += \" AND\"\n",
    "        else:\n",
    "            query_sql += \" WHERE\"\n",
    "        query_sql += \" version LIKE %s\"\n",
    "        params.append(version + '%')\n",
    "    \n",
    "    df = pd.read_sql_query(query_sql, con=engine, params=tuple(params))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data(df = None):\n",
    "    #any rows that are corrupted, either through an error in data write or read, are dropped\n",
    "    df = df.dropna()\n",
    "    \n",
    "    blue_team = ['blue_one','blue_two','blue_three','blue_four', 'blue_five']\n",
    "    red_team = ['red_one', 'red_two', 'red_three', 'red_four', 'red_five']\n",
    "    \n",
    "    blue_team_encoded = np.zeros((len(df),len(all_champions)))\n",
    "    blue_team_columns = [f\"blue_{champ}\" for champ in all_champions]\n",
    "    red_team_encoded = np.zeros((len(df),len(all_champions)))\n",
    "    red_team_columns = [f\"red_{champ}\" for champ in all_champions]\n",
    "\n",
    "    #encode the blue and red champions using bag of words \n",
    "    for idx,row in df.iterrows():\n",
    "        for col in blue_team:\n",
    "            champ = row[col]\n",
    "            champ_index = np.where(all_champions == champ)[0]\n",
    "            blue_team_encoded[idx][champ_index] = 1\n",
    "\n",
    "        for col in red_team: \n",
    "            champ = row[col]\n",
    "            champ_index = np.where(all_champions == champ)[0]\n",
    "            red_team_encoded[idx][champ_index] = 1\n",
    "\n",
    "    #convert encoded data from array to dataframe and concatenate the blue and red team dataframes\n",
    "    #also drop columns we will not be using\n",
    "    blue_team_encoded = pd.DataFrame(blue_team_encoded,columns=blue_team_columns)\n",
    "    red_team_encoded = pd.DataFrame(red_team_encoded, columns=red_team_columns)\n",
    "\n",
    "    match_ids = df['match_id']\n",
    "\n",
    "    df = df.drop(columns=['id','region','match_id','game_mode','elo','version'])\n",
    "    df = df.drop(columns=blue_team)\n",
    "    df = df.drop(columns=red_team)\n",
    "    df = pd.concat([df,blue_team_encoded,red_team_encoded],axis=1)\n",
    "\n",
    "    return df, match_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftAnalysisNN(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(input_size,16,1)\n",
    "        self.conv2 = nn.Conv1d(16,32,1)\n",
    "        self.fc1 = nn.Linear(len(all_champions) * 32,64)\n",
    "        self.fc2 = nn.Linear(64,output_size)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        logits = self.act(self.conv1(input))\n",
    "        logits = self.act(self.conv2(logits))\n",
    "        logits = logits.view(logits.size(0),-1)\n",
    "        logits = self.fc1(logits)\n",
    "        logits = self.fc2(logits)\n",
    "        \n",
    "        output = torch.softmax(logits,dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.label = np.array(df.iloc[:,0])\n",
    "        self.input =  np.array(df.iloc[:,1:df.shape[1]])\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        split = int((self.data.shape[1]-1)/2)\n",
    "        blue_team = self.data.iloc[idx,1:split+1]\n",
    "        red_team = self.data.iloc[idx,split+1:self.data.shape[1]]\n",
    "\n",
    "        blue_team_tensor = torch.tensor(blue_team.values, dtype=torch.float32)\n",
    "        red_team_tensor = torch.tensor(red_team.values, dtype=torch.float32)\n",
    "\n",
    "        input = torch.stack((blue_team_tensor,red_team_tensor),dim=0).to(device)\n",
    "\n",
    "        label = self.data.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
    "        return {\n",
    "            'input': input,\n",
    "            'label' : label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,batch_size):\n",
    "    #split the data of the dataset and array (dataset for nn, array for scipy)\n",
    "    train_indices, test_indices = train_test_split(range(len(data)), test_size=0.2, random_state=42, shuffle=True)\n",
    "    train_dataset = Subset(data, train_indices)\n",
    "    test_dataset = Subset(data, test_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    train_inputs, test_inputs, train_labels, test_labels = train_test_split(data.input, data.label, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    return train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_loader, train_inputs, train_labels, num_epochs, paths):\n",
    "    #training loop\n",
    "    SVC_model = LinearSVC(dual = 'auto')\n",
    "    GNB_model = GaussianNB()\n",
    "    channels = next(iter(train_loader))['input'].shape[1]\n",
    "    NN_model = DraftAnalysisNN(channels,channels).to(device)\n",
    "    \n",
    "    SVC_model.fit(train_inputs,train_labels)\n",
    "    GNB_model.fit(train_inputs,train_labels)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(NN_model.parameters(),lr=1e-5)\n",
    "\n",
    "    print(f'Starting training of {num_epochs} epochs')\n",
    "    NN_model.zero_grad()\n",
    "    NN_model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            input = batch['input']\n",
    "            label = batch['label']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = NN_model(input)\n",
    "            loss = criterion(output,label)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "\n",
    "    #save model\n",
    "    print(f'Saving models')\n",
    "    with open(paths['SVC'], 'wb') as file:\n",
    "        pickle.dump(SVC_model,file)\n",
    "    \n",
    "    with open(paths['GNB'],'wb') as file:\n",
    "        pickle.dump(GNB_model, file)\n",
    "    \n",
    "    torch.save(NN_model.state_dict(),paths['NN'])\n",
    "\n",
    "    #save as onnx\n",
    "    NN_model.eval()\n",
    "    dummy_input = torch.randn(input.shape, requires_grad=True).to(device)\n",
    "\n",
    "    torch.onnx.export(\n",
    "        NN_model,\n",
    "        dummy_input,\n",
    "        paths['NN_ONNX'],\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output']\n",
    "    )\n",
    "\n",
    "    return SVC_model, GNB_model, NN_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels):\n",
    "    #test models\n",
    "    SVC_predictions = SVC_model.predict(test_inputs)\n",
    "    GNB_predictions = GNB_model.predict(test_inputs)\n",
    "    \n",
    "    print('Testing Models')\n",
    "    NN_model.eval()\n",
    "    NN_predictions = []\n",
    "    labels = []\n",
    "    voting_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            input = batch['input']\n",
    "            label = batch['label'].cpu().numpy()\n",
    "\n",
    "            output = NN_model(input)\n",
    "            prediction = torch.argmax(output, dim=1)\n",
    "            NN_pred = prediction.cpu().numpy()\n",
    "            NN_predictions.extend(NN_pred)\n",
    "            labels.extend(label)\n",
    "\n",
    "            sklearn_input = input.flatten().cpu().numpy().reshape((input.shape[0], -1))\n",
    "            SVC_pred = SVC_model.predict(sklearn_input)\n",
    "            GNB_pred = GNB_model.predict(sklearn_input)\n",
    "\n",
    "            #voting implementation\n",
    "            combined_preds = np.stack([NN_pred, SVC_pred, GNB_pred], axis=0)\n",
    "            voting_result = stats.mode(combined_preds)\n",
    "            voting_predictions.extend(voting_result[0])\n",
    "    \n",
    "    SVC_acc = accuracy_score(test_labels,SVC_predictions)\n",
    "    GNB_acc = accuracy_score(test_labels,GNB_predictions)\n",
    "    NN_acc = accuracy_score(labels,NN_predictions)\n",
    "    NN_prec = precision_score(labels,NN_predictions,zero_division=0)\n",
    "    NN_recall = recall_score(labels,NN_predictions,zero_division=0)\n",
    "\n",
    "    voting_acc = accuracy_score(voting_predictions, labels)\n",
    "\n",
    "    print(f'SVC Accuracy: {SVC_acc:.2f}')\n",
    "    print(f'GNB Accuracy: {GNB_acc:.2f}')\n",
    "    print(f'NN Accuracy: {NN_acc:.2f}, NN Precision: {NN_prec:.2f}, NN Recall: {NN_recall:.2f}')\n",
    "    print(f'Voting Accuracy: {voting_acc:.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(SVC_model,GNB_model,NN_model, blue_team, red_team):\n",
    "    #encode the blue_team and red_team inputs\n",
    "    blue_team_encoded = np.zeros(len(all_champions))\n",
    "    red_team_encoded = np.zeros(len(all_champions))\n",
    "\n",
    "    for champ in blue_team:\n",
    "        champ_index = np.where(all_champions == champ)[0]\n",
    "        if champ_index.size == 0:\n",
    "            raise ValueError(f\"Champion '{champ}' not found in list.\")\n",
    "        blue_team_encoded[champ_index] = 1\n",
    "\n",
    "    for champ in red_team:\n",
    "        champ_index = np.where(all_champions == champ)[0]\n",
    "        if champ_index.size == 0:\n",
    "            raise ValueError(f\"Champion '{champ}' not found in list.\")\n",
    "        red_team_encoded[champ_index] = 1\n",
    "\n",
    "    #create sklearn input as a numpy array and pytorch nn input as a tensor\n",
    "    sklearn_input = np.concatenate((blue_team_encoded,red_team_encoded),axis=None).reshape(1,-1)\n",
    "    SVC_pred = SVC_model.predict(sklearn_input)\n",
    "    GNB_pred = GNB_model.predict(sklearn_input)\n",
    "    \n",
    "    nn_input = torch.vstack((torch.tensor(blue_team_encoded),torch.tensor(red_team_encoded))).float().unsqueeze(0).to(device)\n",
    "    output = NN_model(nn_input)\n",
    "    prediction = torch.argmax(output, dim=1)\n",
    "    NN_pred = prediction.cpu().numpy()\n",
    "    #voting implementation\n",
    "    combined_preds = np.stack([NN_pred, SVC_pred, GNB_pred], axis=0)\n",
    "    voting_result = stats.mode(combined_preds)[0]\n",
    "\n",
    "    #print results\n",
    "    if voting_result == 0:\n",
    "        winner = 'Blue Team'\n",
    "    else:\n",
    "        winner = 'Red Team'\n",
    "    \n",
    "    winner = 'Blue Team' if voting_result == 0 else 'Red Team'\n",
    "    \n",
    "    print(f'Predicted winner is {winner}')\n",
    "    print(f'SVC model predicted {\"Blue Team\" if SVC_pred[0] == 0 else \"Red Team\"}')\n",
    "    print(f'GNB model predicted {\"Blue Team\" if GNB_pred[0] == 0 else \"Red Team\"}')\n",
    "    print(f'NN model predicted {\"Blue Team\" if NN_pred[0] == 0 else \"Red Team\"} with a {output[0][0]*100 if NN_pred[0] == 0 else output[0][1]*100:.2f}% chance')\n",
    "\n",
    "    return sklearn_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_game(encoded_data, threshold, inputs, labels, match_ids):\n",
    "    matching_elements = (inputs == 1) & (encoded_data == 1)\n",
    "    match_counts = np.sum(matching_elements, axis=1)\n",
    "    matching_ids = match_ids[match_counts >= threshold]\n",
    "    matching_labels = labels[match_counts >= threshold]\n",
    "    \n",
    "    if matching_ids.empty:\n",
    "        print(f'Found no games with {threshold} or more similar characters')\n",
    "    else:\n",
    "        for idx, id in enumerate(matching_ids):\n",
    "            region, id_num = id.split('_')\n",
    "            if region == 'NA1':\n",
    "                region = 'NA'\n",
    "            region = region.lower()\n",
    "            winner = 'Blue Team' if matching_labels[idx] else 'Red Team'\n",
    "            print(f'https://www.leagueofgraphs.com/match/{region}/{id_num}, {winner} won')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(blue_team, red_team,region='NA1',game_mode='ARAM',elo='ANY',version='14.13', threshold=5, batch_size=1, num_epochs=10, override=False):\n",
    "    #error testing\n",
    "    if len(blue_team) != 5 or len(red_team) != 5:\n",
    "        raise ValueError(\"Both teams must have exactly 5 champions. \"\n",
    "                         f\"Current sizes - Blue team: {len(blue_team)}, Red team: {len(red_team)}\")\n",
    "    if len(blue_team) != len(set(blue_team)):\n",
    "        raise ValueError(\"Duplicate champions found in blue team\")\n",
    "    if len(red_team) != len(set(red_team)):\n",
    "        raise ValueError(\"Duplicate champions found in red team\")\n",
    "    \n",
    "    #label paths\n",
    "    prefix = f'Models/{region}_{game_mode}_{elo}_{version}_'\n",
    "    paths = {\n",
    "        'SVC' : prefix+'svc_model.pkl',\n",
    "        'GNB' : prefix+'gnb_model.pkl',\n",
    "        'NN' : prefix+'nn_model.pth',\n",
    "        'NN_ONNX': prefix+'nn_model.onnx'\n",
    "    }\n",
    "\n",
    "    #gets data\n",
    "    df = get_data(region,game_mode,elo,version)\n",
    "    df, match_ids = verify_data(df)\n",
    "    data = MatchDataset(df) \n",
    "    print(f'Found {len(match_ids)} games with given settings')\n",
    "\n",
    "    #train/test models if it does not exist. Otherwise load models and predict whether blue or red team will win based on the given champions\n",
    "    if(override or not all(os.path.exists(path) for path in paths.values())):\n",
    "        print('Override is true or model(s) missing, training/testing models')\n",
    "        train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels = split_data(data,batch_size)\n",
    "        SVC_model, GNB_model, NN_model = train_models(train_loader,train_inputs, train_labels, num_epochs, paths)\n",
    "        test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels)\n",
    "    else:\n",
    "        print('Models exist, loading models')\n",
    "        with open(paths['SVC'],'rb') as file:\n",
    "            SVC_model = pickle.load(file)\n",
    "    \n",
    "        with open(paths['GNB'],'rb') as file:\n",
    "            GNB_model = pickle.load(file)\n",
    "\n",
    "        NN_model = DraftAnalysisNN(2,2).to(device)\n",
    "        NN_model.load_state_dict(torch.load(paths['NN']))\n",
    "\n",
    "    #prediction\n",
    "    encoded_data = predict(SVC_model,GNB_model,NN_model, blue_team, red_team)\n",
    "    #get old games based on threshold value, if threshold = 5, get all games where 5 champions match up to our 5 champions (on same team)\n",
    "    get_similar_game(encoded_data[0],threshold,data.input,data.label, match_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5072 games with given settings\n",
      "Override is true or model(s) missing, training/testing models\n",
      "Starting training of 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4057/4057 [00:11<00:00, 349.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.6922\n",
      "Saving models\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m blue_team \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKSante\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJhin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMorgana\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYone\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBard\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m red_team \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeeSin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrianna\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeimerdinger\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTristana\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraves\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblue_team\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mred_team\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNA1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mARAM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mANY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m14.13\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(blue_team, red_team, region, game_mode, elo, version, threshold, batch_size, num_epochs, override)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverride is true or model(s) missing, training/testing models\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m     train_loader,test_loader, train_inputs, test_inputs, train_labels, test_labels \u001b[38;5;241m=\u001b[39m split_data(data,batch_size)\n\u001b[1;32m---> 30\u001b[0m     SVC_model, GNB_model, NN_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     test_models(SVC_model,GNB_model, NN_model, test_loader, test_inputs, test_labels)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[44], line 51\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(train_loader, train_inputs, train_labels, num_epochs, paths)\u001b[0m\n\u001b[0;32m     48\u001b[0m NN_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     49\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNN_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNN_ONNX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SVC_model, GNB_model, NN_model\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[0;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:1612\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[0;32m   1609\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1610\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[1;32m-> 1612\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1627\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[0;32m   1628\u001b[0m )\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:1134\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m   1133\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[1;32m-> 1134\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:1010\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m   1005\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[0;32m   1006\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m     )\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1010\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1011\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m   1012\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\onnx\\utils.py:914\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    912\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[0;32m    913\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 914\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[0;32m    923\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\jit\\_trace.py:1310\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m   1309\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m-> 1310\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\jit\\_trace.py:138\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[1;32m--> 138\u001b[0m graph, out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\jit\\_trace.py:129\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[0;32m    128\u001b[0m     inputs_states\u001b[38;5;241m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[1;32m--> 129\u001b[0m outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[0;32m    131\u001b[0m     inputs_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (inputs_states[\u001b[38;5;241m0\u001b[39m], trace_inputs)\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1522\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[1;32mIn[41], line 11\u001b[0m, in \u001b[0;36mDraftAnalysisNN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(logits))\n\u001b[0;32m     13\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1522\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Draft-Analysis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA___slow_conv2d_forward)"
     ]
    }
   ],
   "source": [
    "blue_team = ['KSante','Jhin','Morgana','Yone','Bard']\n",
    "red_team = ['LeeSin','Orianna','Heimerdinger','Tristana','Graves']\n",
    "main(blue_team, red_team,'NA1','ARAM','ANY','14.13', threshold=4, batch_size=1, num_epochs=1, override=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
